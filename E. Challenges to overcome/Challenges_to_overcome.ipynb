{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Challenges to overcome\n"
      ],
      "metadata": {
        "id": "j64rBTsSBwpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Computational time\n"
      ],
      "metadata": {
        "id": "TEOiGnFFBzQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the training process, the model exhibited a consistent training time of approximately 70 seconds per epoch. This seems unexpected due to the relatively small size of the dataset, however, the utilization of data augmentation techniques significantly increased the training data's size. This is most likely the main contributer to the large training duration.\n",
        "\n",
        "\\\n",
        "To address these performance bottlenecks, I employed caching and prefetching mechanisms to optimize image loading speed. Despite these optimizations, the overall training time remained moderate but, in my opinion, still in acceptable limits.\n",
        "\n",
        "\\\n",
        "**Challenge Analysis:**\n",
        "While data augmentation is crucial to improving model generalization, it introduces a computational overhead as the model needs to process a larger volume of data. We are then faced with a trade-off between training time and model performance. I don't mind the 10 minute wait for my model to train if it will be a perfect fit, so I chose the model performance route."
      ],
      "metadata": {
        "id": "SxjI9Xchjp-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Overfitting\n"
      ],
      "metadata": {
        "id": "BhTGcXuDB5a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially my model had high training accuracy and low validation accuracy, this demonstrated tendency towards overfitting. This suggests, my model was memorizing the training examples instead of learning generalized patterns. This would result in poor performance on unseen data. The model was also fluctuating accuracy values significantly indicating the same problem.\n",
        "\n",
        "\\\n",
        "**Mitigation Strategies:**\n",
        "To mitigate overfitting and improve the model's generalization capability, several techniques were eployed. These can be categorized broadly into techniques implemented proactively and those added in response to the observed problem.\n",
        "\n",
        "**Proactive Measures:**\n",
        "1. Data Augmentation - Artificial expansion of the dataset through the introduction of variations of existing training images. This exposes the model to a wider range of potential patterns.\n",
        "2. Normilization - Pixel values were normalized using Z-score normilization. This ensured stable and efficient training by preventing features with larger values from dominating the learning process\n",
        "\n",
        "**Reactive Measures:**\n",
        "1. L2 Regularization - Introduced to penalize large weights within the model, encouraging it to learn simpler patterns and reducing complexity of the learned function. This helps prevent the model from fitting the noise in the training data.\n",
        "2. Dropout - Randomly dropped neurons during training, preventing over-reliance\n",
        "3. Early Stopping - Prevents the model from training for too long by stopping when the validation accuracy plateaus or starts to decrease\n",
        "\n",
        "As a result, I succeeded in improving my validation accuracy, reducing overfitting and having more stabilized learning."
      ],
      "metadata": {
        "id": "YWr7_a4NEBnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Low Performance"
      ],
      "metadata": {
        "id": "EU8_B-PtB-YT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying L2 regularization and dropout I noticed a decrease in model performance/accuracy. To fix this I addressed the values used and lowered the regularizer from `0.01` to `0.001` and decreased the dropout of the dense layers from `0.5` to `0.25` and the dropout of conv layers from `0.25` to `0.15`. This successfully improved my model."
      ],
      "metadata": {
        "id": "Ew-p7w8NFcj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Undesirable Evaluation Metrics"
      ],
      "metadata": {
        "id": "PPlEdDvqCG2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was really confused on how my model could have such great test accuracy but such low evalution metrics. I looked into so many solutions for this and nothing worked. Not until I realized that I had just wrote the code incorrectly. This caused such a headache due to only a miswritten line."
      ],
      "metadata": {
        "id": "57ig72PwgTXN"
      }
    }
  ]
}